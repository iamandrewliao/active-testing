{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example rollout data\n",
    "factor_values = {\n",
    "    \"x\": [0.5, 0.7, 0.4, 0.8],  # x position\n",
    "    \"y\": [0.2, 0.3, 0.1, 0.4],  # y position\n",
    "    }\n",
    "outcomes = [1, 0, 0, 1]  # success = 1\n",
    "# Concatenate factor values and outcomes into training data\n",
    "\n",
    "train_X = torch.tensor([i for i in factor_values.values()]).T.to(torch.double)\n",
    "train_Y = torch.tensor(outcomes).unsqueeze(-1).to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4ceb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): LogNormalPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): SingleTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): RBFKernel(\n",
       "      (lengthscale_prior): LogNormalPrior()\n",
       "      (raw_lengthscale_constraint): GreaterThan(2.500E-02)\n",
       "    )\n",
       "    (outcome_transform): Standardize()\n",
       "    (input_transform): Normalize()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a Gaussian Process model to data (https://botorch.org/docs/models)\n",
    "# SingleTaskGP: a single-task exact GP that supports both inferred and observed noise. When noise observations are not provided, it infers a homoskedastic noise level.\n",
    "# MixedSingleTaskGP: a single-task exact GP that supports mixed search spaces, which combine discrete and continuous features.\n",
    "# SaasFullyBayesianSingleTaskGP: a fully Bayesian single-task GP with the SAAS prior. This model is suitable for sample-efficient high-dimensional Bayesian optimization.\n",
    "# SingleTaskVariationalGP: an approximate model for faster computation when you have a lot of data or your responses are non-Gaussian.\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize\n",
    "from botorch.fit import fit_gpytorch_mll  # fit surrogate model (suitable for exact GPs)\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "gp = SingleTaskGP(\n",
    "    train_X=train_X,\n",
    "    train_Y=train_Y,\n",
    "    input_transform=Normalize(d=2),\n",
    ")\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7903d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an acquisition function (https://botorch.org/docs/acquisition)\n",
    "# Joint Entropy Search (JES)\n",
    "# Bayesian Active Learning By Disagreement (BALD)\n",
    "# GIBBON (General-purpose Information-Based Bayesian OptimisatioN)\n",
    "\n",
    "from botorch.acquisition.utils import get_optimal_samples\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "num_samples = 12\n",
    "\n",
    "# Bounds of the search space. If the model inputs are normalized, the bounds should be normalized as well.\n",
    "bounds = torch.tensor([[-3.0, -3.0], [3.0, 3.0]], **tkwargs)  # 3 std devs\n",
    "\n",
    "optimal_inputs, optimal_outputs = get_optimal_samples(\n",
    "    gp, bounds=bounds, num_optima=num_samples\n",
    ")\n",
    "\n",
    "from botorch.acquisition.joint_entropy_search import qJointEntropySearch\n",
    "\n",
    "jes_lb = qJointEntropySearch(\n",
    "    model=gp,\n",
    "    optimal_inputs=optimal_inputs,\n",
    "    optimal_outputs=optimal_outputs,\n",
    "    estimation_type=\"LB\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cec73ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JES-LB: candidate=tensor([[0.9966, 2.1044]], dtype=torch.float64), acq_value=0.20906776660708734\n"
     ]
    }
   ],
   "source": [
    "# Optimize the acquisition function\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    acq_function=jes_lb,\n",
    "    bounds=bounds,\n",
    "    q=1,\n",
    "    num_restarts=4,\n",
    "    raw_samples=256,\n",
    ")\n",
    "print(\"JES-LB: candidate={}, acq_value={}\".format(candidate, acq_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_testing",
   "language": "python",
   "name": "active_testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
